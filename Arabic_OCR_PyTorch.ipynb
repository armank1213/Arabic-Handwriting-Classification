{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicCharDataset(Dataset):\n",
    "    def __init__(self, image_file, label_file, transform=None):\n",
    "        self.images = pd.read_csv(image_file, header=None).values\n",
    "        self.labels = pd.read_csv(label_file, header=None).values.ravel() - 1  # Subtract 1 to make labels 0-indexed\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(32, 32).astype(np.float32) / 255.0\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicCharNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ArabicCharNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 28 \n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArabicCharDataset('data/csvTrainImages 13440x1024.csv', 'data/csvTrainLabel 13440x1.csv', transform=transform)\n",
    "test_dataset = ArabicCharDataset('data/csvTestImages 3360x1024.csv', 'data/csvTestLabel 3360x1.csv', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/210], Loss: 2.3677\n",
      "Epoch [1/10], Step [200/210], Loss: 1.0746\n",
      "Epoch [2/10], Step [100/210], Loss: 0.6783\n",
      "Epoch [2/10], Step [200/210], Loss: 0.5828\n",
      "Epoch [3/10], Step [100/210], Loss: 0.4275\n",
      "Epoch [3/10], Step [200/210], Loss: 0.3890\n",
      "Epoch [4/10], Step [100/210], Loss: 0.3203\n",
      "Epoch [4/10], Step [200/210], Loss: 0.3119\n",
      "Epoch [5/10], Step [100/210], Loss: 0.2452\n",
      "Epoch [5/10], Step [200/210], Loss: 0.2510\n",
      "Epoch [6/10], Step [100/210], Loss: 0.2097\n",
      "Epoch [6/10], Step [200/210], Loss: 0.1999\n",
      "Epoch [7/10], Step [100/210], Loss: 0.1733\n",
      "Epoch [7/10], Step [200/210], Loss: 0.1792\n",
      "Epoch [8/10], Step [100/210], Loss: 0.1253\n",
      "Epoch [8/10], Step [200/210], Loss: 0.1447\n",
      "Epoch [9/10], Step [100/210], Loss: 0.1096\n",
      "Epoch [9/10], Step [200/210], Loss: 0.1334\n",
      "Epoch [10/10], Step [100/210], Loss: 0.1053\n",
      "Epoch [10/10], Step [200/210], Loss: 0.1028\n",
      "Test Accuracy: 95.06%\n"
     ]
    }
   ],
   "source": [
    "model = ArabicCharNet(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "train(model, train_loader, criterion, optimizer, device)\n",
    "evaluate(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Arabic_OCR_PyTorch.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(model, csv_file, row_index, transform, device):\n",
    "    model.eval()\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    image = df.iloc[row_index].values.reshape(32, 32).astype(np.float32) / 255.0\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    return f\"Detected Arabic character: {predicted.item() + 1}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Arabic character: 9\n",
      "The detected Arabic character is: ذ\n",
      "The detected Arabic character (in english) is: thal\n"
     ]
    }
   ],
   "source": [
    "result = classify_image(model, 'data/csvTestImages 3360x1024.csv', 16, transform, device)\n",
    "print(result)\n",
    "\n",
    "import re\n",
    "\n",
    "number_match = re.search(r'\\d+', result)\n",
    "if number_match:\n",
    "    result_index = int(number_match.group()) - 1  \n",
    "else:\n",
    "    print(\"Error: Could not extract a number from the result\")\n",
    "    result_index = -1\n",
    "\n",
    "arabic_chars = 'أبتثجحخدذرزسشصضطظعغفقكلمنهوي'\n",
    "arabic_characters = ['alef', 'beh', 'teh', 'theh', 'jeem', 'hah', 'khah', 'dal', 'thal',\n",
    "                    'reh', 'zain', 'seen', 'sheen', 'sad', 'dad', 'tah', 'zah', 'ain',\n",
    "                    'ghain', 'feh', 'qaf', 'kaf', 'lam', 'meem', 'noon', 'heh', 'waw', 'yeh']\n",
    "\n",
    "if 0 <= result_index < len(arabic_chars):\n",
    "    print(f\"The detected Arabic character is: {arabic_chars[result_index]}\")\n",
    "    print(f\"The detected Arabic character (in english) is: {arabic_characters[result_index]}\")\n",
    "else:\n",
    "    print(f\"Error: Invalid index {result_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
